{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644359a-4e02-4e11-a6ae-4e2d6dcca078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "from operator import add\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb53b8e-83a5-4e3d-a6c6-6b646363d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108770b2-98b4-40f9-a1f6-2ed2e85d19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    train_imaegs = sorted(glob(os.path.join(data_path, \"training\", \"images\", \"*.tif\")))\n",
    "    train_masks = sorted(glob(os.path.join(data_path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    test_images = sorted(glob(os.path.join(data_path, \"test\", \"images\", \"*.tif\")))\n",
    "    test_masks = sorted(glob(os.path.join(data_path, \"test\", \"1st_manual\", \"*.gif\")))\n",
    "\n",
    "    return (train_imaegs, train_masks), (test_images, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b07e4fd-5313-47c2-a9f2-cd623304f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmenteation(images, masks, save_path, augment=True):\n",
    "    size = (512, 512)\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = imageio.mimread(y)[0]\n",
    "        print(f\"X shape : {x.shape}, y shape :{y.shape}\")\n",
    "\n",
    "        index = 0\n",
    "        if augment == True:\n",
    "            \n",
    "            aug = HorizontalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "\n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented[\"image\"]\n",
    "            y2 = augmented[\"mask\"]\n",
    "\n",
    "            aug = Rotate(limit=45, p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented[\"image\"]\n",
    "            y3 = augmented[\"mask\"]\n",
    "\n",
    "            X = [x, x1, x2, x3]\n",
    "            Y = [y, y1, y2, y3]\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "\n",
    "        for i, m in zip(X, Y):\n",
    "            i = cv2.resize(i, size)\n",
    "            m = cv2.resize(m, size)\n",
    "\n",
    "            tem_image_name = f\"{name}_{index}.png\"\n",
    "            tem_mask_name = f\"{name}_{index}.png\"\n",
    "\n",
    "            image_path = os.path.join(save_path, \"Training_augmented_data\", \"images\", tem_image_name)\n",
    "            mask_path = os.path.join(save_path, \"Training_augmented_data\", \"masks\", tem_mask_name)\n",
    "\n",
    "            images = cv2.imwrite(image_path, i)\n",
    "            masks = cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1\n",
    "            \n",
    "        \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a367ef-dff0-4ac9-b9f4-071feb930959",
   "metadata": {},
   "source": [
    "# Building the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f5168-25c0-4d4a-b410-402c2da21cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channel, output_channel, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(output_channel)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(output_channel, output_channel, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channel)\n",
    "        \n",
    "        self.activation1 = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb46c46-780d-4638-b4e9-3a2f4dcb31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super().__init__()\n",
    "        self.conv = ConvBlock(input_channel, output_channel)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d260fc-b160-4a5b-937a-a2196ab2923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super().__init__()\n",
    "        self.conv_transpose = nn.ConvTranspose2d(input_channel, output_channel, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = ConvBlock(output_channel + output_channel, output_channel)\n",
    "\n",
    "    def forward(self, inputs, skip_connection):\n",
    "        x = self.conv_transpose(inputs)\n",
    "        x = torch.cat([x, skip_connection], axis=1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93246a-dee8-49c5-805d-bd9f7875a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = EncoderBlock(3, 64)\n",
    "        self.e2 = EncoderBlock(64, 128)\n",
    "        self.e3 = EncoderBlock(128, 256)\n",
    "        self.e4 = EncoderBlock(256, 512)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        self.b = ConvBlock(512, 1024)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.decoder = Decoder(1024, 512)\n",
    "        self.decoder2 = Decoder(512, 256)\n",
    "        self.decoder3 = Decoder(256, 128)\n",
    "        self.decoder4 = Decoder(128, 64)\n",
    "\n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        \"\"\" Bottleneck \"\"\"\n",
    "        b = self.b(p4)\n",
    "        # print(s1.shape, s2.shape, s3.shape, s4.shape)\n",
    "        # print(b.shape)\n",
    "\n",
    "        d1 = self.decoder(b, s4)\n",
    "        d2 = self.decoder2(d1, s3)\n",
    "        d3 = self.decoder3(d2, s2)\n",
    "        d4 = self.decoder4(d3, s1)\n",
    "        #print(d1.shape)\n",
    "        print(d4.shape)\n",
    "\n",
    "        outputs = self.outputs(d4)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e59ee9-4362-44c9-896c-687a8c7d38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        # Flatten label and prediction tensors\n",
    "        inputs = inputs.veiw(-1)\n",
    "        targets = targets.veiw(-1)\n",
    "\n",
    "        intersection = (inputs * traget).sum()\n",
    "        dice = (2. * intersection + smooth) / ( inputs.sum() + targets.sum() + smooth)\n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6102def-d6d5-492f-894c-4256ce43f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        # Flatten label and prediction tensors\n",
    "        inputs = inputs.veiw(-1)\n",
    "        targets = targets.veiw(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (inputs.sum() + targets.sum())\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction=\"mean\")\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964bc2b-2b71-4152-af99-7aaad501a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, image_path, mask_path):\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.n_samples = len(image_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading Image \"\"\"\n",
    "        image = cv2.imread(self.image_path[index], cv2.IMREAD_COLOR)\n",
    "        image = image / 255.0\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = image.astype(np.float32)\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        \"\"\" Reading Mask \"\"\"\n",
    "        mask = cv2.imread(self.mask_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babf05b-1e7f-4073-866c-0e1c3938d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "    return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071146d4-a83e-4d76-b421-58c51cc86952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea9022-8220-47e7-a5ee-e3cfc25e57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_time, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638acff3-de57-425e-a61c-55671403b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn((2, 3, 512, 512))\n",
    "    print(x.shape)\n",
    "    f = BuildUNet()\n",
    "    y = f(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304dca33-1202-41f3-9106-5564ae97e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn((2, 32, 128, 128))\n",
    "    f = ConvBlock(32, 64)\n",
    "    y = f(x)\n",
    "    print(y.shape)\n",
    "\n",
    "    e = EncoderBlock(32, 64)\n",
    "    encoder, decoder = e(x)\n",
    "    print(encoder.shape, decoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867bd79-b604-408b-86f8-fef86f626223",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\\blood\\DRIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa6753-9075-4300-8045-55d8fb7f128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \"\"\" Load the data \"\"\"\n",
    "    data_path = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\\blood\\DRIVE\"\n",
    "    (train_imaegs, train_masks), (test_images, test_masks) = load_data(data_path)\n",
    "    print(f\"Training images : {len(train_imaegs)}, Training masks : {len(train_masks)}\")\n",
    "    print(f\"Test images : {len(test_images)}, Test masks : {len(test_masks)}\")\n",
    "\n",
    "    \"\"\" Creating some folders for saving the augmented dataset \"\"\"\n",
    "    create_dir(data_path + \"\\\\Training_augmented_data\")\n",
    "    create_dir(data_path + \"\\\\Training_augmented_data\" + \"\\\\images\")\n",
    "    create_dir(data_path + \"\\\\Training_augmented_data\" + \"\\\\masks\")\n",
    "    data_augmenteation(train_imaegs, train_masks, data_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf1fde-8420-4518-bc0f-a13665e23a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss = loss.item()\n",
    "\n",
    "    epoch_loss = epoch_loss / len(loader) \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b229e3-98e3-41f1-b51b-e2ef9a1b4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "        epoch_loss = epoch_loss / len(loader) \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd6224-7764-42cd-a5ca-cda67c0a67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Directories \"\"\"\n",
    "    create_dir(data_path + \"\\\\files\")\n",
    "\n",
    "    \"\"\" Loading dataset \"\"\"\n",
    "    augmented_data_path = r\"E:\\python\\segmentation\\Computer Vision\\UNET\\data\\blood\\DRIVE\"\n",
    "    X_train = sorted(glob(augmented_data_path + \"\\\\Training_augmented_data\\\\images\\\\*\"))\n",
    "    y_train = sorted(glob(augmented_data_path + \"\\\\Training_augmented_data\\\\masks\\\\*\"))\n",
    "\n",
    "    X_val = sorted(glob(data_path + \"\\\\test\\\\images\\\\*\"))\n",
    "    y_val = sorted(glob(data_path + \"\\\\test\\\\masks\\\\*\"))\n",
    "    print(f\"Dataset Size:\\n Train: {len(X_train)} \\n Valid : {len(X_val)}\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H, W = 512, 512\n",
    "    size = (H, W)\n",
    "    batch_size = 2\n",
    "    num_epochs = 52\n",
    "    lr = 1e-4\n",
    "    checkpoint_path = data_path + \"\\\\files\\\\Retina_Blood_Vessel_with_pytorch.pth\"\n",
    "\n",
    "    \"\"\" Dataset and Loader \"\"\"\n",
    "    train_dataset = DriveDataset(X_train, y_train)\n",
    "    val_dataset = DriveDataset(X_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = BuildUNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=5, verbose=True)\n",
    "\n",
    "    loss_fn = DiceBCELoss()\n",
    "\n",
    "    \"\"\" Training The Model \"\"\"\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_loss = evaluate(model, val_loader, loss_fn, device)\n",
    "\n",
    "        \"\"\" Saving the Model \"\"\"\n",
    "        if val_loss < best_valid_loss:\n",
    "            data_str = f\"Valid loss improve from {best_valid_loss:2.4f} to {val_loss:2.4f}\"\n",
    "            print(data_str)\n",
    "\n",
    "            best_valid_loss = val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        data_str = f\"Epoch: {epoch+1:02} | Epoch Time : {epoch_mins}m {epoch_secs}\"\n",
    "        data_str = f\"\\tTrain loss: {train_loss:.3f}\\n\"\n",
    "        data_str = f\"\\t Val loss : {val_loss:.3f}\\n\"\n",
    "        print(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978525e-6c3d-4f48-b71a-47887aebaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" Ground Truth \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    jaccard = jaccard_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return [jaccard, f1, recall, precision, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d80008-a10e-42a1-a960-dcd1c8c681de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fe2ed-ea0a-49b2-accd-7ff69366759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    seeding(42)\n",
    "\n",
    "    \"\"\" Folders \"\"\"\n",
    "    create_dir(data_path + \"\\\\results\")\n",
    "\n",
    "    \"\"\" Load dataset \"\"\"\n",
    "    X_test = sorted(glob(data_path + \"\\\\test\\\\image\\\\*\"))\n",
    "    y_test = sorted(glob(data_path + \"\\\\test\\\\mask\\\\*\"))\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    H, W = 512, 512\n",
    "    size = (H, W)\n",
    "    checkpoint_path = data_path + \"\\\\files\\\\checkpoint.pth\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = BuildUNet()\n",
    "    model = mode.to(device)\n",
    "    mode.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    time_taken = []\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(zip(X_test, y_test)), total=len(X_test)):\n",
    "        \"\"\" Extracting the Name \"\"\"\n",
    "        name = y.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading Images \"\"\"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        # image = cv2.reaise(image, size)\n",
    "        x = np.transpose(image, (2, 0, 1))\n",
    "        x = x / 255.0\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        x = x.to(device)\n",
    "\n",
    "        \"\"\" Reading Masks \"\"\"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "        #mask = cv2.resize(mask, size)\n",
    "        y = np.expand_dims(y, axis=0)\n",
    "        y = y / 255.0\n",
    "        y = np.expand_dims(y, axis=0)\n",
    "        y = y.astype(np.float32)\n",
    "        y = torch.from_numpy(y)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \"\"\" Prediction and Calculation FPS \"\"\"\n",
    "            start_time = time.time()\n",
    "            y_pred = model(x)\n",
    "            y_pred = torch.sigmoid(y_pred)\n",
    "            total_time = time.time() - start_time\n",
    "            time_taken.append(total_time)\n",
    "\n",
    "            score = calculate_metrics(y, y_pred)\n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            y_pred = y_pred[0].cpu().numpy()\n",
    "            y_pred = np.squeeze(y_pred, axis=0)\n",
    "            y_pred = y_pred > 0.5\n",
    "            y_pred = np.array(y_perd, dtype=np.uint8)\n",
    "\n",
    "        \"\"\" Saving masks \"\"\"\n",
    "        ori_mask = mask_parse(mask)\n",
    "        y_pred = mask_parse(y_pred)\n",
    "        line = np.ones((size[1], 10, 3)) * 128\n",
    "\n",
    "        cat_images = np.concatenate(\n",
    "            [image, line, ori_mask, line, y_pred * 255], axis=1\n",
    "        )\n",
    "        cv2.imwrite(data_path + f\"\\\\results\\\\{name}.pnt\", cat_images)\n",
    "\n",
    "    jaccard = metrics_score[0] / len(X_test)\n",
    "    f1 = metrics_score[1] / len(X_test)\n",
    "    recall = metrics_score[2] / len(X_test)\n",
    "    precision = metrics_score[3] / len(X_test)\n",
    "    acc = metrics_score[4] / len(X_test)\n",
    "    print(f\"Jaccard: {jaccard:1.4f} - F1:{f1:1.4f} - Recall:{recall:1.4f} - Precision:{precision:1.4f} - Accuracy:{acc:1.4f}\")\n",
    "\n",
    "    fps = 1 / np.mean(time_taken)\n",
    "    print(\"FPS: \", fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee11c6-58a3-443d-ba4d-4afc31427048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
